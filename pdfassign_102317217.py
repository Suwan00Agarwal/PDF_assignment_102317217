# -*- coding: utf-8 -*-
"""PDFAssign_102317217.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iC2apdKntGjRJA2VAYKYF7Vzgb8M6O5b
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import files
files.upload()

data = pd.read_csv("data.csv", encoding="latin1")
print(data.head())

data.sample(500).to_csv("data_sample.csv", index=False)

print(data.columns)

x = data['no2'].dropna()
print(x.isna().sum())
print(len(x))
x_np = x.to_numpy()

a_r = 1.0
b_r = 0.9
z = x_np + a_r * np.sin(b_r * x_np)
print(z[:5])
print(z.shape)

import torch
import torch.nn as nn
import torch.optim as optim

z_tensor = torch.tensor(z, dtype=torch.float32)
z_tensor = z_tensor.view(-1, 1)
print(z_tensor.shape)
print(z_tensor[:5])

class Generator(nn.Module):
    def __init__(self, noise_dim):
        super(Generator, self).__init__()

        self.model = nn.Sequential(
            nn.Linear(noise_dim, 16),
            nn.ReLU(),
            nn.Linear(16, 16),
            nn.ReLU(),
            nn.Linear(16, 1)
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.model = nn.Sequential(
            nn.Linear(1, 16),
            nn.ReLU(),
            nn.Linear(16, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

noise_dim = 5
learning_rate = 0.001

generator = Generator(noise_dim)
discriminator = Discriminator()

criterion = nn.BCELoss()

optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)
optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)

epochs = 3000
batch_size = 64
real_label = 1.0
fake_label = 0.0

idx = torch.randint(0, z_tensor.size(0), (batch_size,))
real_z = z_tensor[idx]
print(real_z.shape)
print(real_z[:5])

noise = torch.randn(batch_size, noise_dim)
fake_z = generator(noise)
print(fake_z.shape)
print(fake_z[:5])

for epoch in range(epochs):

    # Training Discriminator
    idx = torch.randint(0, z_tensor.size(0), (batch_size,))
    real_z = z_tensor[idx]
    real_labels = torch.ones(batch_size, 1)

    noise = torch.randn(batch_size, noise_dim)
    fake_z = generator(noise)
    fake_labels = torch.zeros(batch_size, 1)

    d_real = discriminator(real_z)
    d_fake = discriminator(fake_z.detach())

    d_loss_real = criterion(d_real, real_labels)
    d_loss_fake = criterion(d_fake, fake_labels)
    d_loss = d_loss_real + d_loss_fake

    optimizer_D.zero_grad()
    d_loss.backward()
    optimizer_D.step()

    #Training Generator
    noise = torch.randn(batch_size, noise_dim)
    fake_z = generator(noise)
    g_labels = torch.ones(batch_size, 1)

    g_loss = criterion(discriminator(fake_z), g_labels)

    optimizer_G.zero_grad()
    g_loss.backward()
    optimizer_G.step()

    if epoch % 500 == 0:
        print(f"Epoch {epoch} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}")

with torch.no_grad():
    noise = torch.randn(10000, noise_dim)
    z_fake = generator(noise).numpy().flatten()

from scipy.stats import gaussian_kde

kde = gaussian_kde(z_fake)
z_range = np.linspace(z_fake.min(), z_fake.max(), 500)
pdf_estimated = kde(z_range)

plt.figure(figsize=(8, 5))
plt.plot(z_range, pdf_estimated, label="GAN Estimated PDF")
plt.xlabel("z")
plt.ylabel("Density")
plt.title("Estimated PDF of Transformed Variable z using GAN")
plt.legend()
plt.grid(True)
plt.show()

